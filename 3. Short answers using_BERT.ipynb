{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm import tqdm_notebook as tqdm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setting up Hugging Face BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer, TFBertForQuestionAnswering \n\nmodelName = 'bert-large-uncased-whole-word-masking-finetuned-squad' # https://huggingface.co/transformers/pretrained_models.html\n \ntokenizer = BertTokenizer.from_pretrained(modelName)\nmodel = TFBertForQuestionAnswering.from_pretrained(modelName)","execution_count":2,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ced743d2f09c46cea72cf2857a4d0921"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01eed0c59dc4259bcd0da86cab97f21"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1341090760.0, style=ProgressStyle(descr…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de44c5e582294c718014688f73aacd03"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Loading Test Data and Previous Submission Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = '../input/tensorflow2-question-answering/simplified-nq-test.jsonl'\ntest = pd.read_json(test_path, orient='records', lines=True, dtype={'example_id':np.dtype('object')})\nsubmission = pd.read_csv(\"../input/baseline-lstm/submission.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                   example_id PredictionString\n0   -1011141123527297803_long         931:1088\n1  -1011141123527297803_short         931:1088\n2   -1028916936938579349_long          781:923\n3  -1028916936938579349_short          781:923\n4   -1055197305756217938_long          741:998","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1011141123527297803_long</td>\n      <td>931:1088</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1011141123527297803_short</td>\n      <td>931:1088</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1028916936938579349_long</td>\n      <td>781:923</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1028916936938579349_short</td>\n      <td>781:923</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1055197305756217938_long</td>\n      <td>741:998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"- Note that every short answer till now is equal to the long answer.\n- I predict short answer using that long answer as the text to the question.\n- i.e my short answer is a subset to the long answer."},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_predict_short_answer(q, t, base):\n    \"\"\"\n    Predict the answer tokens for the given question and text.\n    parameters: \n        question: question\n        text: corresponding text\n    returns:\n        predicted answer tokens\n    \"\"\"\n    try:\n        input_text =  q + \" [SEP] \" + t \n        input_ids = tokenizer.encode(input_text)\n        input = tf.constant(input_ids)[None, :]  # Batch size 1 \n        token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n\n        startScores, endScores =model(input, token_type_ids = tf.convert_to_tensor([token_type_ids]))\n        startIdx = tf.math.argmax(startScores[0],0).numpy()\n        endIdx = tf.math.argmax(endScores[0],0).numpy()+1\n        # print(startIdx,endIdx)\n        # input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n        # print(\" \".join(input_tokens[startIdx:endIdx]))\n        return str(startIdx+base) +':' + str(endIdx+base)\n    except:\n        return np.nan\n    \n    \ndef predict(submission, test):\n    \"\"\"\n    Modifies the short answer in the submission file.\n    Using that long answer as the Text to the Question, my BERT model will predict a subset of indies that i will consider my short answer.\n    Parameters:\n        submission: submission file to be modified\n        test: The test file\n    Returns: \n        Returns Modified submission file.\n    \"\"\"\n    short = '_short' \n    for i in tqdm(range(len(submission))):\n        if submission.iloc[i]['example_id'].endswith(short):\n            id = submission.iloc[i]['example_id'][:-6]\n            token = submission.iloc[i]['PredictionString']\n\n            if isinstance(token, str): # https://www.geeksforgeeks.org/python-check-if-a-variable-is-string/\n                # sample dataframe corresponding to the id\n                sample_df = test[test['example_id'] == id]\n                # Text of the sample df\n                text = sample_df.iloc[0]['document_text'].split()\n                # Corresponding Question \n                question = sample_df.iloc[0]['question_text'] \n                \n                # start: the token before \":\", end: the token after \":\"\n                index = token.index(':')\n                start = int(token[:index])\n                end = int(token[index+1:])\n                \n                # text corresponds to the long answer\n                text = \" \".join(text[start:end])\n                \n                # Tokens for the short answer.\n                token = bert_predict_short_answer(question, text, base = start)\n                \n            else:\n                # No long answer.\n                token = np.nan\n            submission.iloc[i]['PredictionString'] = str(token)\n    return submission","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = predict(submission, test)","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=692.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d02250bdbe24adc8cf538dc2912fb5e"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                   example_id PredictionString\n0   -1011141123527297803_long         931:1088\n1  -1011141123527297803_short          932:941\n2   -1028916936938579349_long          781:923\n3  -1028916936938579349_short          797:818\n4   -1055197305756217938_long          741:998","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1011141123527297803_long</td>\n      <td>931:1088</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1011141123527297803_short</td>\n      <td>932:941</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1028916936938579349_long</td>\n      <td>781:923</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1028916936938579349_short</td>\n      <td>797:818</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1055197305756217938_long</td>\n      <td>741:998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the short answer is modified by our BERT model."},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission = (\n    submission.drop(columns='PredictionString').merge(submission, on=['example_id'], how='left')\n) \nfinal_submission.to_csv(\"submission.csv\", index=False)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                   example_id PredictionString\n0   -1011141123527297803_long         931:1088\n1  -1011141123527297803_short          932:941\n2   -1028916936938579349_long          781:923\n3  -1028916936938579349_short          797:818\n4   -1055197305756217938_long          741:998","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1011141123527297803_long</td>\n      <td>931:1088</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1011141123527297803_short</td>\n      <td>932:941</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1028916936938579349_long</td>\n      <td>781:923</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1028916936938579349_short</td>\n      <td>797:818</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1055197305756217938_long</td>\n      <td>741:998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}