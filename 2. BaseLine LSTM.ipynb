{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Baseline Modeling"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing import text, sequence\nimport fasttext","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# https://stackoverflow.com/questions/20885797/iteratively-parse-json-file\ndef build_train(train_path, n_rows=200000, sampling_rate=15):\n    with open(train_path) as f:\n        processed_rows = []\n\n        for i in tqdm(range(n_rows)):\n            line = f.readline()\n            if not line:\n                break\n\n            line = json.loads(line)\n\n            text = line['document_text'].split(' ')\n            question = line['question_text']\n            annotations = line['annotations'][0]\n\n            for i, candidate in enumerate(line['long_answer_candidates']):\n                label = i == annotations['long_answer']['candidate_index']\n\n                start = candidate['start_token']\n                end = candidate['end_token']\n\n                if label or (i % sampling_rate == 0):\n                    processed_rows.append({\n                        'text': \" \".join(text[start:end]),\n                        'is_long_answer': label,\n                        'question': question,\n                        'annotation_id': annotations['annotation_id']\n                    })\n\n        train = pd.DataFrame(processed_rows)\n        \n        return train","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_test(test_path):\n    with open(test_path) as f:\n        processed_rows = []\n\n        for line in tqdm(f):\n            line = json.loads(line)\n\n            text = line['document_text'].split(' ')\n            question = line['question_text']\n            example_id = line['example_id']\n\n            for candidate in line['long_answer_candidates']:\n                start = candidate['start_token']\n                end = candidate['end_token']\n\n                processed_rows.append({\n                    'text': \" \".join(text[start:end]),\n                    'question': question,\n                    'example_id': example_id,\n                    'sequence': f'{start}:{end}'\n\n                })\n\n        test = pd.DataFrame(processed_rows)\n    \n    return test","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = '/kaggle/input/tensorflow2-question-answering/'\ntrain_path = directory + 'simplified-nq-train.jsonl'\ntest_path = directory + 'simplified-nq-test.jsonl'\n\ntrain = build_train(train_path)\ntest = build_test(test_path)\ntrain_target = train.is_long_answer.astype(int).values","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=200000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be973338b874b46a3ecaaadacbdd5be"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b15d3168c9d40adae2ca5c5230dc184"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(5)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                                      text  is_long_answer  \\\n1807747               <Li> Welkom Hoërskool , Welkom </Li>           False   \n1541210  <Li> Jump up ^ `` Diaghilev London Walk '' . V...           False   \n210418   <Table> British Columbia Liberal Party leaders...            True   \n107785   <Tr> <Th> Slovakia ( Singles Digitál Top 100 )...           False   \n1590139  <P> The 21 World Cup tournaments have been won...            True   \n\n                                                  question  \\\n1807747  list of agricultural high schools in south africa   \n1541210  at its first performance the rite of spring pr...   \n210418   who won the liberal leadership in british colu...   \n107785       justin bieber i'll show you mp3 song download   \n1590139   which african country has ever won the world cup   \n\n                annotation_id  \n1807747  17414750892970110456  \n1541210   2290474378537056466  \n210418    4027934080044497844  \n107785   10991333931554020085  \n1590139  13524104377121675701  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>is_long_answer</th>\n      <th>question</th>\n      <th>annotation_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1807747</th>\n      <td>&lt;Li&gt; Welkom Hoërskool , Welkom &lt;/Li&gt;</td>\n      <td>False</td>\n      <td>list of agricultural high schools in south africa</td>\n      <td>17414750892970110456</td>\n    </tr>\n    <tr>\n      <th>1541210</th>\n      <td>&lt;Li&gt; Jump up ^ `` Diaghilev London Walk '' . V...</td>\n      <td>False</td>\n      <td>at its first performance the rite of spring pr...</td>\n      <td>2290474378537056466</td>\n    </tr>\n    <tr>\n      <th>210418</th>\n      <td>&lt;Table&gt; British Columbia Liberal Party leaders...</td>\n      <td>True</td>\n      <td>who won the liberal leadership in british colu...</td>\n      <td>4027934080044497844</td>\n    </tr>\n    <tr>\n      <th>107785</th>\n      <td>&lt;Tr&gt; &lt;Th&gt; Slovakia ( Singles Digitál Top 100 )...</td>\n      <td>False</td>\n      <td>justin bieber i'll show you mp3 song download</td>\n      <td>10991333931554020085</td>\n    </tr>\n    <tr>\n      <th>1590139</th>\n      <td>&lt;P&gt; The 21 World Cup tournaments have been won...</td>\n      <td>True</td>\n      <td>which african country has ever won the world cup</td>\n      <td>13524104377121675701</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"                                                text  \\\n0  <Table> <Tr> <Th_colspan=\"2\"> High Commission ...   \n1  <Tr> <Th_colspan=\"2\"> High Commission of South...   \n2  <Tr> <Th> Location </Th> <Td> Trafalgar Square...   \n3  <Tr> <Th> Address </Th> <Td> Trafalgar Square ...   \n4  <Tr> <Th> Coordinates </Th> <Td> 51 ° 30 ′ 30 ...   \n\n                                            question            example_id  \\\n0  who is the south african high commissioner in ...  -1220107454853145579   \n1  who is the south african high commissioner in ...  -1220107454853145579   \n2  who is the south african high commissioner in ...  -1220107454853145579   \n3  who is the south african high commissioner in ...  -1220107454853145579   \n4  who is the south african high commissioner in ...  -1220107454853145579   \n\n  sequence  \n0   18:136  \n1    19:30  \n2    34:45  \n3    45:59  \n4   59:126  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>question</th>\n      <th>example_id</th>\n      <th>sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; High Commission ...</td>\n      <td>who is the south african high commissioner in ...</td>\n      <td>-1220107454853145579</td>\n      <td>18:136</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; High Commission of South...</td>\n      <td>who is the south african high commissioner in ...</td>\n      <td>-1220107454853145579</td>\n      <td>19:30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;Tr&gt; &lt;Th&gt; Location &lt;/Th&gt; &lt;Td&gt; Trafalgar Square...</td>\n      <td>who is the south african high commissioner in ...</td>\n      <td>-1220107454853145579</td>\n      <td>34:45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;Tr&gt; &lt;Th&gt; Address &lt;/Th&gt; &lt;Td&gt; Trafalgar Square ...</td>\n      <td>who is the south african high commissioner in ...</td>\n      <td>-1220107454853145579</td>\n      <td>45:59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;Tr&gt; &lt;Th&gt; Coordinates &lt;/Th&gt; &lt;Td&gt; 51 ° 30 ′ 30 ...</td>\n      <td>who is the south african high commissioner in ...</td>\n      <td>-1220107454853145579</td>\n      <td>59:126</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array([0, 0, 0, ..., 1, 0, 0])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_avg_length(df):\n    length = []\n    df.apply(lambda x: length.append(len(x.split())))\n    return np.mean(length)\n\ndef count_less_than_x(df, thr):\n    temp = df.apply(lambda x: True if len(x.split())>thr else False)\n    count = temp[temp == False]\n    return (len(count)*100)/len(df)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The average length of all the document_text is {}\".format(find_avg_length(train['text'])))","execution_count":9,"outputs":[{"output_type":"stream","text":"The average length of all the document_text is 86.9223448525609\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [100, 200, 250, 300, 350, 400]:\n    print(\"Percentage of documents with length less than {}: {}\".format(i, count_less_than_x(train['text'], i)))","execution_count":10,"outputs":[{"output_type":"stream","text":"Percentage of documents with length less than 100: 77.94376116706712\nPercentage of documents with length less than 200: 91.82614912177553\nPercentage of documents with length less than 250: 94.70552242362689\nPercentage of documents with length less than 300: 96.26487945030713\nPercentage of documents with length less than 350: 97.24196205304415\nPercentage of documents with length less than 400: 97.83677585114253\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The average length of all the Question_text is {}\".format(find_avg_length(train['question'])))","execution_count":11,"outputs":[{"output_type":"stream","text":"The average length of all the Question_text is 9.19653882054959\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [10, 15, 20, 25]:\n    print(\"Percentage of Question with length less than {}: {}\".format(i, count_less_than_x(train['question'], i)))","execution_count":12,"outputs":[{"output_type":"stream","text":"Percentage of Question with length less than 10: 83.60692756196063\nPercentage of Question with length less than 15: 98.81807293233004\nPercentage of Question with length less than 20: 99.99412054240858\nPercentage of Question with length less than 25: 100.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def texts_to_sequences(train, test, tokenizer):\n    train_text = tokenizer.texts_to_sequences(train.text.values)\n    train_questions = tokenizer.texts_to_sequences(train.question.values)\n    test_text = tokenizer.texts_to_sequences(test.text.values)\n    test_questions = tokenizer.texts_to_sequences(test.question.values)\n    return train_text, train_questions, test_text, test_questions\ndef pad_sequence(train_, test_, padding_var = 20):\n    \n    train_var = sequence.pad_sequences(train_, maxlen=padding_var) \n    test_var = sequence.pad_sequences(test_, maxlen=padding_var) \n    return train_var, test_var","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Build_dataset(train, test):\n    print(\"=\"*100)\n    print(\"Tokenizing the sequences...\")\n    tokenizer = text.Tokenizer(lower=False, num_words=80000)\n    \n    t = train['text'].append(train['question'], ignore_index=True).to_frame(name = 'text')\n    tokenizer.fit_on_texts(t['text'])\n    print(\"Done\")\n    print(\"=\"*100)\n    print()\n    print(\"Starting Text to sequences process...\")\n    train_text, train_questions, test_text, test_questions = texts_to_sequences(train, test, tokenizer)\n    print(\"Done\")\n    print(\"=\"*100)\n    print()\n    \n    print(\"Padding Each Sequences...\")\n    train_text, test_text = pad_sequence(train_text, test_text, 300)\n    train_questions, test_questions = pad_sequence(train_questions, test_questions, 20)\n    print(\"Done\")\n    return train_text, train_questions, test_text, test_questions, tokenizer","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text, train_questions, test_text, test_questions, tokenizer = Build_dataset(train, test)","execution_count":15,"outputs":[{"output_type":"stream","text":"====================================================================================================\nTokenizing the sequences...\nDone\n====================================================================================================\n\nStarting Text to sequences process...\nDone\n====================================================================================================\n\nPadding Each Sequences...\nDone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# saving\nwith open('tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_questions[0]","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"array([    0,     0,     0,     0,     0,     0,     0,     0,    43,\n          13,     3,    78,   648,   255,     6, 22867,     8,   586,\n        6071,  4866], dtype=int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_embedding_matrix(tokenizer, path):\n    embedding_matrix = np.zeros((tokenizer.num_words + 1, 300))\n    ft_model = fasttext.load_model(path)\n\n    for word, i in tokenizer.word_index.items():\n        if i >= tokenizer.num_words - 1:\n            break\n        embedding_matrix[i] = ft_model.get_word_vector(word)\n    \n    return embedding_matrix","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(embedding_matrix):\n    embedding = Embedding(\n        *embedding_matrix.shape, \n        weights=[embedding_matrix], \n        trainable=False, \n        mask_zero=True\n    )\n    \n    q_in = Input(shape=(None,))\n    q = embedding(q_in)\n    q = SpatialDropout1D(0.2)(q)\n    q = Bidirectional(LSTM(100, return_sequences=True))(q)\n    q = GlobalMaxPooling1D()(q)\n    \n    \n    t_in = Input(shape=(None,))\n    t = embedding(t_in)\n    t = SpatialDropout1D(0.2)(t)\n    t = Bidirectional(LSTM(150, return_sequences=True))(t)\n    t = GlobalMaxPooling1D()(t)\n    \n    x = concatenate([q, t])\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    \n    out = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs=[t_in, q_in], outputs=out)\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n\n    return model","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/fasttext-crawl-300d-2m-with-subword/crawl-300d-2m-subword/crawl-300d-2M-subword.bin'\nembedding_matrix = build_embedding_matrix(tokenizer, path)","execution_count":21,"outputs":[{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(embedding_matrix)\nmodel.summary()","execution_count":22,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, None, 300)    24000300    input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nspatial_dropout1d (SpatialDropo (None, None, 300)    0           embedding[0][0]                  \n__________________________________________________________________________________________________\nspatial_dropout1d_1 (SpatialDro (None, None, 300)    0           embedding[1][0]                  \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   (None, None, 200)    320800      spatial_dropout1d[0][0]          \n__________________________________________________________________________________________________\nbidirectional_1 (Bidirectional) (None, None, 300)    541200      spatial_dropout1d_1[0][0]        \n__________________________________________________________________________________________________\nglobal_max_pooling1d (GlobalMax (None, 200)          0           bidirectional[0][0]              \n__________________________________________________________________________________________________\nglobal_max_pooling1d_1 (GlobalM (None, 300)          0           bidirectional_1[0][0]            \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 500)          0           global_max_pooling1d[0][0]       \n                                                                 global_max_pooling1d_1[0][0]     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 512)          256512      concatenate[0][0]                \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 512)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            257         dropout_1[0][0]                  \n==================================================================================================\nTotal params: 25,250,397\nTrainable params: 1,250,097\nNon-trainable params: 24,000,300\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfilepath=\"training_1/weights-improvement-{epoch:02d}.ckpt\"\ncheckpoint_dir = os.path.dirname(filepath)\n# Create a callback that saves the model's weights\ncp_callback = ModelCheckpoint(filepath=filepath,save_weights_only=True, verbose=1, save_best_only=True)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    [train_text, train_questions], \n    train_target,\n    epochs=2,\n    validation_split=0.2,\n    batch_size=256# ,callbacks=[cp_callback]  \n    \n)","execution_count":29,"outputs":[{"output_type":"stream","text":"Train on 1537556 samples, validate on 384390 samples\nEpoch 1/2\n1537556/1537556 [==============================] - 6529s 4ms/sample - loss: 0.1325 - val_loss: 0.1185\nEpoch 2/2\n1537556/1537556 [==============================] - 6524s 4ms/sample - loss: 0.1175 - val_loss: 0.1090\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Save Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model.h5')","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference Step"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_target = model.predict([test_text, test_questions], batch_size=256)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['target'] = test_target\n\nresult = (\n    test.query('target > 0.05').groupby('example_id').max().reset_index().loc[:, ['example_id', 'sequence']]\n)\n\nresult = pd.concat([\n    result.assign(example_id=lambda example_id: example_id + '_long'),\n    result.assign(example_id=lambda example_id: example_id + '_short')\n])\n\nresult.head()","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"                  example_id  sequence\n0  -1011141123527297803_long  931:1088\n1  -1028916936938579349_long   781:923\n2  -1055197305756217938_long   741:998\n3  -1074129516932871805_long    89:103\n4  -1114334749483663139_long  968:1083","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_id</th>\n      <th>sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1011141123527297803_long</td>\n      <td>931:1088</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1028916936938579349_long</td>\n      <td>781:923</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1055197305756217938_long</td>\n      <td>741:998</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1074129516932871805_long</td>\n      <td>89:103</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1114334749483663139_long</td>\n      <td>968:1083</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.shape","execution_count":104,"outputs":[{"output_type":"execute_result","execution_count":104,"data":{"text/plain":"(686, 2)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/tensorflow2-question-answering/sample_submission.csv\")\nfinal_submission = (\n    submission.drop(columns='PredictionString').merge(result, on=['example_id'], how='left')\n)\nfinal_submission = final_submission.rename(columns={'sequence': 'PredictionString'})\nfinal_submission.to_csv(\"submission.csv\", index=False) ","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission.head()","execution_count":103,"outputs":[{"output_type":"execute_result","execution_count":103,"data":{"text/plain":"                   example_id PredictionString\n0   -1011141123527297803_long         931:1088\n1  -1011141123527297803_short         931:1088\n2   -1028916936938579349_long          781:923\n3  -1028916936938579349_short          781:923\n4   -1055197305756217938_long          741:998","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1011141123527297803_long</td>\n      <td>931:1088</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1011141123527297803_short</td>\n      <td>931:1088</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1028916936938579349_long</td>\n      <td>781:923</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1028916936938579349_short</td>\n      <td>781:923</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1055197305756217938_long</td>\n      <td>741:998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
